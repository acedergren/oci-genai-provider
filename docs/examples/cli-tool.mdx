---
title: OCI TUI
tldr: A standalone CLI and interactive chat interface for OCI Generative AI models.
business_value: Rapid prototyping and testing of OCI models without writing code.
complexity: low
last_verified: 2026-01-30
stakeholder_relevant: true
dependencies:
  - '@acedergren/oci-genai-provider'
  - commander
  - inquirer
  - pino
---

# OCI TUI

## TL;DR

**What**: A robust command-line interface for interacting with OCI Generative AI services.
**Why**: Enables developers to quickly test prompts, compare model performance, and explore reasoning capabilities directly from the terminal.
**How**: Built using Node.js, Commander, and the OCI GenAI Provider, with support for standalone binary compilation via Bun.
**Dependencies**: `@acedergren/oci-genai-provider`, `ai`, `pino`, `commander`, `inquirer`, `chalk`.

## Setup

The CLI tool is located in `examples/cli-tool`. Ensure you have your OCI credentials configured (`~/.oci/config`).

```bash
cd examples/cli-tool
pnpm install
export OCI_COMPARTMENT_ID=ocid1.compartment.oc1..xxxxx
```

## Usage

### One-Shot Query

Use the `ask` command for quick questions.

```bash
pnpm dev ask "What is the capital of Sweden?"
```

### Interactive Chat

Use the `chat` command for a full REPL experience.

```bash
pnpm dev chat --llama
```

### Advanced Features

Enable reasoning or vision with specialized flags.

```bash
# High effort reasoning with Gemini
pnpm dev ask --gemini --reasoning=high "Solve the Trolley Problem."

# Use Command A Reasoning model
pnpm dev ask --think "Explain quantum computing."
```

## Model Switches

| Flag       | Model                                | Description               |
| :--------- | :----------------------------------- | :------------------------ |
| `--grok`   | `xai.grok-4`                         | Latest Grok model         |
| `--llama`  | `meta.llama-3.3-70b-instruct`        | Most widely available     |
| `--gemini` | `google.gemini-2.5-flash`            | Fast with 1M context      |
| `--cohere` | `cohere.command-r-plus`              | Enterprise-ready Cohere   |
| `--think`  | `cohere.command-a-reasoning-08-2025` | Dedicated reasoning model |

## Agentic Mode (Local Tools)

The CLI tool includes an experimental "Agentic Mode" that allows the model to use local system tools. Enable it with the `--agent` flag.

```bash
# Ask the AI to check your system specs
./oci-tui ask --agent "How much free memory is available on this machine?"

# List files in a directory
./oci-tui ask --agent "List the files in the current folder."
```

### Available Tools

| Tool                  | Description                                     |
| :-------------------- | :---------------------------------------------- |
| `getSystemInfo`       | Returns platform, arch, CPUs, and memory info.  |
| `listDirectory`       | Lists files and folders in a specified path.    |
| `executeShellCommand` | Executes safe shell commands (read-only focus). |

> [!CAUTION]
> **Safety First**: The `executeShellCommand` tool has basic filters but still allows arbitrary command execution. Use with caution in agentic mode.

## Configuration & Logging

### Environment Variables

- `OCI_COMPARTMENT_ID`: **Required**. Your OCI Compartment OCID.
- `OCI_REGION`: Optional. Defaults to `eu-frankfurt-1`.
- `OCI_MODEL_ID`: Optional. Defaults to Llama 3.3.
- `LOG_LEVEL`: Control logging detail (`info`, `debug`, `error`).

### Structured Logs

The tool uses [Pino](https://getpino.io) for structured logging. In development mode, logs are pretty-printed for readability. Detailed usage statistics (tokens, costs) are logged after every successful request.

## Standalone Executable

You can compile the CLI into a standalone binary using Bun:

```bash
pnpm bundle
./oci-tui ask "Hello world"
```

## Known Issues

### Punycode Deprecation

You may see a `DeprecationWarning: The punycode module is deprecated`. This is a known issue in Node.js 21+ caused by transitive dependencies in the OCI SDK and other libraries. It does not affect the functionality of the tool.
