# OCI GenAI Provider - Use Cases & Tutorials

> Step-by-step tutorials and real-world use case implementations

This file contains practical examples and comprehensive tutorials for using the OCI GenAI provider.

## Info

- **Focus**: Hands-on tutorials and production use cases
- **Difficulty**: Beginner to advanced
- **Region**: eu-frankfurt-1 (all examples)

## Tutorials

### Tutorial 1: Basic Chat

**File**: /docs/tutorials/01-basic-chat.md

**What you'll learn**:
- Create provider instance
- Simple text generation
- Handle responses

**Code**:
```typescript
import { createOCI } from '@acedergren/oci-genai-provider';
import { generateText } from 'ai';

const oci = createOCI({
  region: 'eu-frankfurt-1',
  profile: 'DEFAULT',
});

const { text } = await generateText({
  model: oci('cohere.command-r-plus'),
  prompt: 'Explain Oracle Cloud Infrastructure in one paragraph',
});

console.log(text);
```

**Duration**: 5 minutes
**Prerequisites**: OCI account, configured credentials

---

### Tutorial 2: Streaming Responses

**File**: /docs/tutorials/02-streaming-responses.md

**What you'll learn**:
- Real-time streaming
- Web server integration (Express)
- Server-Sent Events (SSE)

**Basic Streaming**:
```typescript
import { streamText } from 'ai';

const { textStream } = await streamText({
  model: oci('cohere.command-r-plus'),
  prompt: 'Write a story about AI',
});

for await (const textPart of textStream) {
  process.stdout.write(textPart);
}
```

**Web Server Example**:
```typescript
import express from 'express';

app.post('/api/chat', async (req, res) => {
  res.setHeader('Content-Type', 'text/event-stream');

  const { textStream } = await streamText({
    model: oci('xai.grok-4-maverick'),
    prompt: req.body.prompt,
  });

  for await (const text of textStream) {
    res.write(`data: ${JSON.stringify({ text })}\n\n`);
  }

  res.end();
});
```

**Duration**: 15 minutes
**Prerequisites**: Tutorial 1 complete

---

### Tutorial 3: Tool Calling

**File**: /docs/tutorials/03-tool-calling.md

**What you'll learn**:
- Define tools with Zod schemas
- Function calling integration
- Tool execution patterns

**Example**:
```typescript
import { generateText, tool } from 'ai';
import { z } from 'zod';

const tools = {
  getWeather: tool({
    description: 'Get current weather',
    inputSchema: z.object({
      location: z.string().describe('City name'),
    }),
    execute: async ({ location }) => ({
      location,
      temperature: 22,
      conditions: 'Sunny',
    }),
  }),
};

const { text } = await generateText({
  model: oci('cohere.command-r-plus'),
  prompt: "What's the weather in Frankfurt?",
  tools,
});

console.log(text);
```

**Duration**: 20 minutes
**Prerequisites**: Tutorial 2 complete

---

### Tutorial 4: OpenCode Integration

**File**: /docs/tutorials/04-opencode-integration.md

**What you'll learn**:
- Install provider globally
- Configure OpenCode
- Use with OpenCode CLI

**Configuration** (`~/.opencode/config.json`):
```json
{
  "providers": {
    "oci-genai": {
      "type": "custom",
      "package": "@acedergren/oci-genai-provider",
      "region": "eu-frankfurt-1"
    }
  },
  "models": {
    "oci-llama": {
      "provider": "oci-genai",
      "model": "meta.llama-3.3-70b-instruct"
    }
  }
}
```

**Usage**:
```bash
npm install -g @acedergren/oci-genai-provider
opencode --model oci-llama
> Write a TypeScript function
```

**Duration**: 10 minutes
**Prerequisites**: OpenCode installed

---

### Tutorial 5: GitHub Bot

**File**: /docs/tutorials/05-github-bot.md

**What you'll learn**:
- GitHub Actions integration
- AI code review
- CI/CD automation

**GitHub Workflow** (`.github/workflows/ai-review.yml`):
```yaml
name: AI Code Review
on: [pull_request]

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup OCI
        run: |
          mkdir -p ~/.oci
          echo "${{ secrets.OCI_CONFIG }}" > ~/.oci/config

      - name: Review Code
        run: |
          npm install @acedergren/oci-genai-provider ai
          node review.js
        env:
          OCI_REGION: eu-frankfurt-1
```

**Review Script** (`review.js`):
```javascript
import { createOCI } from '@acedergren/oci-genai-provider';
import { generateText } from 'ai';
import { execFileSync } from 'child_process';

const oci = createOCI({ region: 'eu-frankfurt-1' });

const diff = execFileSync('git', ['diff', 'HEAD~1'],
  { encoding: 'utf-8' }
);

const { text } = await generateText({
  model: oci('xai.grok-4-maverick'),
  prompt: `Review this code:\n${diff}`,
});

console.log(text);
```

**Duration**: 30 minutes
**Prerequisites**: GitHub repository, secrets configured

---

### Tutorial 6: Production Deployment

**File**: /docs/tutorials/06-production-deployment.md

**What you'll learn**:
- Production configuration
- Dedicated clusters
- Error handling
- Monitoring

**Production Setup**:
```typescript
const oci = createOCI({
  region: 'eu-frankfurt-1',
  auth: 'instance_principal', // For OCI Compute
  servingMode: 'DEDICATED',
  endpointId: process.env.OCI_ENDPOINT_ID,
});
```

**Robust Error Handling**:
```typescript
async function robustGenerate(prompt: string) {
  let retries = 3;
  while (retries > 0) {
    try {
      return await generateText({
        model: oci('meta.llama-3.3-70b-instruct'),
        prompt,
      });
    } catch (error: any) {
      if (error.statusCode === 429) {
        await sleep(2 ** (3 - retries) * 1000);
        retries--;
      } else {
        throw error;
      }
    }
  }
}
```

**Production Checklist**:
- [ ] Use dedicated AI clusters
- [ ] Implement retry logic
- [ ] Set up monitoring/logging
- [ ] Use instance/resource principals
- [ ] Configure rate limiting
- [ ] Set appropriate timeouts
- [ ] Enable audit logging
- [ ] Document runbooks

**Duration**: 45 minutes
**Prerequisites**: All previous tutorials

---

## Use Cases

### Use Case 1: Code Generation

**File**: /docs/use-cases/code-generation/README.md

**Overview**: Generate high-quality code using Grok 4 Maverick with dynamic model selection

**Key Features**:
- Fast code generation
- Multi-language support
- Context-aware suggestions
- Streaming output

**Model Selection**:
- **Primary**: Grok 4 Maverick (speed + quality)
- **Alternative**: Llama 3.3 70B (cost-effective)
- **Complex**: Command A Reasoning (architectural decisions)

**Example Use Cases**:
- Function generation
- Bug fixing
- Code refactoring
- Documentation generation
- Test writing

**Implementation**:
```typescript
async function generateCode(task: string, language: string) {
  const model = selectModelForCodeGen(task);

  const { text } = await generateText({
    model: oci(model),
    prompt: `Generate ${language} code for: ${task}`,
  });

  return text;
}

function selectModelForCodeGen(task: string): string {
  if (task.includes('architecture') || task.includes('design')) {
    return 'cohere.command-a-reasoning';
  }
  return 'xai.grok-4-maverick'; // Default for speed
}
```

**Best Practices**:
- Use streaming for immediate feedback
- Include context in prompts
- Validate generated code
- Use tools for execution/testing

---

### Use Case 2: Office Automation

**File**: /docs/use-cases/office-automation/README.md

**Overview**: Automate document processing and office workflows

**Key Features**:
- Batch document processing
- Template generation
- Data extraction
- Multi-format support

**Model Selection**:
- **Documents**: Cohere Command R+ (RAG-optimized)
- **Fast processing**: Gemini Flash Lite
- **Vision**: Gemini Flash (scanned docs)

**OpenWork Integration**:
```typescript
import { createOCI } from '@acedergren/oci-genai-provider';
import { generateText } from 'ai';

async function processDocuments(documents: string[]) {
  const oci = createOCI({ region: 'eu-frankfurt-1' });

  const results = await Promise.all(
    documents.map(async (doc) => {
      const { text } = await generateText({
        model: oci('cohere.command-r-plus'),
        prompt: `Summarize this document: ${doc}`,
      });
      return text;
    })
  );

  return results;
}
```

**Use Cases**:
- Email summarization
- Report generation
- Meeting notes extraction
- Contract analysis
- Invoice processing

---

### Use Case 3: CI/CD Integration

**File**: /docs/use-cases/cicd-integration/README.md

**Overview**: Integrate AI capabilities into CI/CD pipelines

**Key Features**:
- Automated code review
- Security scanning
- Documentation generation
- Test generation

**GitHub Actions Example**:
```yaml
name: AI Pipeline
on: [push, pull_request]

jobs:
  ai-tasks:
    runs-on: ubuntu-latest
    steps:
      - name: Code Review
        run: |
          npm install @acedergren/oci-genai-provider ai
          node scripts/ai-review.js
        env:
          OCI_REGION: eu-frankfurt-1
          OCI_CONFIG_PROFILE: CI
```

**Security Best Practices**:
- Use GitHub Secrets for credentials
- Instance principals in OCI
- Rate limiting
- Error handling
- Audit logging

**Model Selection**:
- **Code review**: Grok 4 Maverick
- **Security**: Command A Reasoning
- **Documentation**: Gemini Flash

---

## Complete Tutorial Path

**Beginner Path** (1-2 hours):
1. Tutorial 1: Basic Chat (5 min)
2. Tutorial 2: Streaming (15 min)
3. Tutorial 4: OpenCode Integration (10 min)

**Intermediate Path** (2-3 hours):
1. All beginner tutorials
2. Tutorial 3: Tool Calling (20 min)
3. Use Case 1: Code Generation

**Advanced Path** (4+ hours):
1. All intermediate tutorials
2. Tutorial 5: GitHub Bot (30 min)
3. Tutorial 6: Production Deployment (45 min)
4. All use cases

## Related Documentation

- API Reference: llms-api-reference.txt
- Model Selection: llms-models.txt
- Implementation Guides: llms-guides.txt
