# OCI GenAI Provider - Implementation Guides

> Step-by-step guides for authentication, streaming, tool calling, and integrations

This file covers all implementation guides needed to build and deploy the provider.

## Info

- **Focus**: How-to guides for core functionality
- **Audience**: Developers implementing the provider
- **Region Focus**: eu-frankfurt-1 (Frankfurt)

## Authentication Guide

Complete authentication implementation guide:

- Main Guide: /docs/guides/authentication/README.md

**Authentication Methods Covered**:
1. **API Key Authentication** (development)
   - Config file format (~/.oci/config)
   - Multiple profiles
   - Environment variables

2. **Instance Principal** (OCI Compute)
   - Dynamic groups
   - Instance authentication
   - No credentials in config

3. **Resource Principal** (OCI Functions)
   - Serverless authentication
   - Function-level permissions
   - Automatic token management

**Configuration Cascade**:
```
Environment Variables → Constructor Options → Config File → Defaults
```

**Security Best Practices**:
- File permissions (chmod 600)
- Key rotation schedule
- Compartment isolation
- Least privilege policies

## IAM Policy Guide

Complete IAM policy setup and troubleshooting:

- Main Guide: /docs/guides/iam-policies/README.md
- Policy Templates: /docs/guides/iam-policies/required-policies.md

**Common Scenarios**:
- Development environment setup
- Production workloads
- CI/CD pipelines
- OCI Compute instances
- OCI Functions

**Copy-Paste Ready Templates**:
```
Allow group Developers to use generative-ai-family in compartment AI-Development
Allow group Developers to read compartments in compartment AI-Development
```

**Troubleshooting**:
- 403 Forbidden → Missing policies
- 401 Unauthorized → Auth configuration
- Compartment OCID issues
- Regional availability

## Streaming Guide

Complete streaming implementation with SSE:

- Main Guide: /docs/guides/streaming/README.md

**Key Topics**:
- Server-Sent Events protocol
- eventsource-parser library usage
- Async iterator patterns
- Backpressure handling
- Error recovery in streams
- Performance optimization

**Implementation Pattern**:
```typescript
import { EventSourceParser, createParser } from 'eventsource-parser';

const parser: EventSourceParser = createParser((event) => {
  if (event.type === 'event') {
    const data = JSON.parse(event.data);
    // Process streaming data
  }
});

// Feed parser with SSE chunks
for await (const chunk of response.body) {
  parser.feed(decoder.decode(chunk));
}
```

**Best Practices**:
- Chunked encoding support
- Graceful disconnection
- Timeout handling
- Token buffering strategies

## Tool Calling Guide

Function calling and tool integration:

- Main Guide: /docs/guides/tool-calling/README.md

**Key Topics**:
- AI SDK tool definition format (Zod schemas)
- OCI GenAI tool format conversion
- Tool execution patterns
- Error handling for tool failures
- Security considerations (use execFile for commands)

**Security-Aware Patterns**:
```typescript
import { execFile } from 'child_process';
import { promisify } from 'util';

const execFileAsync = promisify(execFile);

// Safe - separate command and args prevents injection
await execFileAsync('git', ['status', '--porcelain']);
```

**Tool Schema Conversion**:
- Zod → JSON Schema → OCI GenAI parameters
- Type safety and validation
- Parameter descriptions for LLMs

## OpenCode Integration Guide

Complete OpenCode provider integration:

- Main Guide: /docs/guides/opencode-integration/README.md
- Configuration: /docs/guides/opencode-integration/configuration.md

**Setup Process**:
1. Install provider package
2. Configure OpenCode config.json
3. Define model aliases
4. Test with OpenCode CLI

**Configuration Example** (Frankfurt-focused):
```json
{
  "providers": {
    "oci-genai": {
      "type": "custom",
      "package": "@acedergren/oci-genai-provider",
      "region": "eu-frankfurt-1",
      "profile": "FRANKFURT"
    }
  },
  "models": {
    "oci-llama": {
      "provider": "oci-genai",
      "model": "meta.llama-3.3-70b-instruct"
    },
    "oci-grok": {
      "provider": "oci-genai",
      "model": "xai.grok-4-maverick"
    }
  }
}
```

**Testing**:
```bash
opencode --model oci-llama
> Write a TypeScript function to parse JSON
```

## Deployment Guide

Production deployment best practices:

- Main Guide: /docs/guides/deployment/ (referenced in tutorials)

**Key Topics**:
- Environment configuration
- Dedicated vs on-demand clusters
- Monitoring and logging
- Rate limiting
- Retry strategies
- Circuit breakers

**Production Checklist**:
- [ ] Use dedicated AI clusters
- [ ] Implement retry logic
- [ ] Set up monitoring/logging
- [ ] Use instance/resource principals
- [ ] Configure rate limiting
- [ ] Set appropriate timeouts
- [ ] Enable audit logging
- [ ] Document runbooks

## Monitoring Guide

Observability and debugging:

- Main Guide: /docs/guides/monitoring/ (referenced in tutorials)

**Metrics to Track**:
- Token usage per request
- Latency (P50, P95, P99)
- Error rates by type
- Model selection frequency
- Cost per request

**Logging Best Practices**:
```typescript
import { Logger } from 'winston';

const logger = new Logger();

const { text, usage } = await generateText({
  model: oci('cohere.command-r-plus'),
  prompt,
});

logger.info('Generation complete', {
  model: 'cohere.command-r-plus',
  tokens: usage.totalTokens,
  duration: performance.now(),
  region: 'eu-frankfurt-1',
});
```

## Related Documentation

- API Reference: llms-api-reference.txt
- Model Selection: llms-models.txt
- Tutorials: llms-use-cases.txt
